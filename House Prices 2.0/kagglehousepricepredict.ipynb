{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5407,"databundleVersionId":868283,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport os\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torch import nn\nfrom sklearn.model_selection import train_test_split\n\ninput_dir = '/kaggle/input/house-prices-advanced-regression-techniques/'","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LgFmOzP784T9","outputId":"d241161f-b636-4402-cb10-b513cf22851c","trusted":true,"execution":{"iopub.status.busy":"2025-07-31T15:36:17.747453Z","iopub.execute_input":"2025-07-31T15:36:17.747721Z","iopub.status.idle":"2025-07-31T15:36:27.433661Z","shell.execute_reply.started":"2025-07-31T15:36:17.747697Z","shell.execute_reply":"2025-07-31T15:36:27.432924Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"def read_and_preprocess_csv(input_dir):\n    '''\n    Reads and preprocesses train and test csv's\n\n    Args:\n        input_dir (str): directory of the house prices dataset\n\n    Returns:\n        X_train (pd.DataFrame): input for the model training\n        y_train (pd.Series): labels for training\n        X_test (pd.DataFrame): input for the model testing\n    '''\n    train_csv = pd.read_csv(os.path.join(input_dir, 'train.csv'))\n    test_csv = pd.read_csv(os.path.join(input_dir, 'test.csv'))\n\n    ground_truth = 'SalePrice'\n\n    features = pd.concat(\n        (train_csv.drop(columns=['Id', ground_truth]),\n         test_csv.drop(columns=['Id']))\n    )\n\n    numerical_features = features.dtypes[features.dtypes != 'object'].index\n\n    features[numerical_features] = features[numerical_features].fillna(features[numerical_features].mean())\n\n    features = pd.get_dummies(features, dummy_na=True)\n        \n    scaler = StandardScaler()\n    features = pd.DataFrame(scaler.fit_transform(features), columns=features.columns)\n\n    features = features.astype('float32')\n    \n    y_train = np.log1p(train_csv[ground_truth])\n    # y_train = train_csv[ground_truth]\n\n    X_train = features.iloc[:len(y_train)]\n    X_test = features.iloc[len(y_train):]\n\n    return X_train, y_train, X_test\n\nX_train_df, y_train_df, X_test_df = read_and_preprocess_csv(input_dir)\n\nprint(f'X_train shape: {X_train_df.shape}, y_train shape: {y_train_df.shape}, X_test shape: {X_test_df.shape}')\n\nX_train_df","metadata":{"id":"9mMrwzBX87Rt","trusted":true,"execution":{"iopub.status.busy":"2025-07-31T15:36:27.434528Z","iopub.execute_input":"2025-07-31T15:36:27.434960Z","iopub.status.idle":"2025-07-31T15:36:27.707030Z","shell.execute_reply.started":"2025-07-31T15:36:27.434930Z","shell.execute_reply":"2025-07-31T15:36:27.706350Z"}},"outputs":[{"name":"stdout","text":"X_train shape: (1460, 330), y_train shape: (1460,), X_test shape: (1459, 330)\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"      MSSubClass  LotFrontage   LotArea  OverallQual  OverallCond  YearBuilt  \\\n0       0.067331    -0.202068 -0.217879     0.646183    -0.507284   1.046258   \n1      -0.873616     0.501870 -0.072044    -0.063185     2.188279   0.154764   \n2       0.067331    -0.061280  0.137197     0.646183    -0.507284   0.980221   \n3       0.302568    -0.436714 -0.078385     0.646183    -0.507284  -1.859351   \n4       0.067331     0.689587  0.518903     1.355551    -0.507284   0.947203   \n...          ...          ...       ...          ...          ...        ...   \n1455    0.067331    -0.342855 -0.285470    -0.063185    -0.507284   0.914184   \n1456   -0.873616     0.736516  0.381311    -0.063185     0.391237   0.220801   \n1457    0.302568    -0.155138 -0.142806     0.646183     3.086800  -1.000876   \n1458   -0.873616    -0.061280 -0.057207    -0.772552     0.391237  -0.703711   \n1459   -0.873616     0.267224 -0.029308    -0.772552     0.391237  -0.208437   \n\n      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  SaleType_Oth  \\\n0         0.896833    0.525202    0.580907   -0.293130  ...     -0.049029   \n1        -0.395604   -0.572250    1.178112   -0.293130  ...     -0.049029   \n2         0.848965    0.334828    0.097873   -0.293130  ...     -0.049029   \n3        -0.682812   -0.572250   -0.494941   -0.293130  ...     -0.049029   \n4         0.753229    1.387486    0.468931   -0.293130  ...     -0.049029   \n...            ...         ...         ...         ...  ...           ...   \n1455      0.753229   -0.572250   -0.969192   -0.293130  ...     -0.049029   \n1456      0.178812    0.094060    0.765338    0.670525  ...     -0.049029   \n1457      1.040437   -0.572250   -0.365400   -0.293130  ...     -0.049029   \n1458      0.561757   -0.572250   -0.861608    5.790313  ...     -0.049029   \n1459     -0.922153   -0.572250    0.853162    1.421349  ...     -0.049029   \n\n      SaleType_WD  SaleType_nan  SaleCondition_Abnorml  SaleCondition_AdjLand  \\\n0        0.395018     -0.018512              -0.263861              -0.064249   \n1        0.395018     -0.018512              -0.263861              -0.064249   \n2        0.395018     -0.018512              -0.263861              -0.064249   \n3        0.395018     -0.018512               3.789876              -0.064249   \n4        0.395018     -0.018512              -0.263861              -0.064249   \n...           ...           ...                    ...                    ...   \n1455     0.395018     -0.018512              -0.263861              -0.064249   \n1456     0.395018     -0.018512              -0.263861              -0.064249   \n1457     0.395018     -0.018512              -0.263861              -0.064249   \n1458     0.395018     -0.018512              -0.263861              -0.064249   \n1459     0.395018     -0.018512              -0.263861              -0.064249   \n\n      SaleCondition_Alloca  SaleCondition_Family  SaleCondition_Normal  \\\n0                 -0.09105             -0.126535              0.463937   \n1                 -0.09105             -0.126535              0.463937   \n2                 -0.09105             -0.126535              0.463937   \n3                 -0.09105             -0.126535             -2.155466   \n4                 -0.09105             -0.126535              0.463937   \n...                    ...                   ...                   ...   \n1455              -0.09105             -0.126535              0.463937   \n1456              -0.09105             -0.126535              0.463937   \n1457              -0.09105             -0.126535              0.463937   \n1458              -0.09105             -0.126535              0.463937   \n1459              -0.09105             -0.126535              0.463937   \n\n      SaleCondition_Partial  SaleCondition_nan  \n0                 -0.302693                0.0  \n1                 -0.302693                0.0  \n2                 -0.302693                0.0  \n3                 -0.302693                0.0  \n4                 -0.302693                0.0  \n...                     ...                ...  \n1455              -0.302693                0.0  \n1456              -0.302693                0.0  \n1457              -0.302693                0.0  \n1458              -0.302693                0.0  \n1459              -0.302693                0.0  \n\n[1460 rows x 330 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MSSubClass</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>OverallQual</th>\n      <th>OverallCond</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>MasVnrArea</th>\n      <th>BsmtFinSF1</th>\n      <th>BsmtFinSF2</th>\n      <th>...</th>\n      <th>SaleType_Oth</th>\n      <th>SaleType_WD</th>\n      <th>SaleType_nan</th>\n      <th>SaleCondition_Abnorml</th>\n      <th>SaleCondition_AdjLand</th>\n      <th>SaleCondition_Alloca</th>\n      <th>SaleCondition_Family</th>\n      <th>SaleCondition_Normal</th>\n      <th>SaleCondition_Partial</th>\n      <th>SaleCondition_nan</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.067331</td>\n      <td>-0.202068</td>\n      <td>-0.217879</td>\n      <td>0.646183</td>\n      <td>-0.507284</td>\n      <td>1.046258</td>\n      <td>0.896833</td>\n      <td>0.525202</td>\n      <td>0.580907</td>\n      <td>-0.293130</td>\n      <td>...</td>\n      <td>-0.049029</td>\n      <td>0.395018</td>\n      <td>-0.018512</td>\n      <td>-0.263861</td>\n      <td>-0.064249</td>\n      <td>-0.09105</td>\n      <td>-0.126535</td>\n      <td>0.463937</td>\n      <td>-0.302693</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.873616</td>\n      <td>0.501870</td>\n      <td>-0.072044</td>\n      <td>-0.063185</td>\n      <td>2.188279</td>\n      <td>0.154764</td>\n      <td>-0.395604</td>\n      <td>-0.572250</td>\n      <td>1.178112</td>\n      <td>-0.293130</td>\n      <td>...</td>\n      <td>-0.049029</td>\n      <td>0.395018</td>\n      <td>-0.018512</td>\n      <td>-0.263861</td>\n      <td>-0.064249</td>\n      <td>-0.09105</td>\n      <td>-0.126535</td>\n      <td>0.463937</td>\n      <td>-0.302693</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.067331</td>\n      <td>-0.061280</td>\n      <td>0.137197</td>\n      <td>0.646183</td>\n      <td>-0.507284</td>\n      <td>0.980221</td>\n      <td>0.848965</td>\n      <td>0.334828</td>\n      <td>0.097873</td>\n      <td>-0.293130</td>\n      <td>...</td>\n      <td>-0.049029</td>\n      <td>0.395018</td>\n      <td>-0.018512</td>\n      <td>-0.263861</td>\n      <td>-0.064249</td>\n      <td>-0.09105</td>\n      <td>-0.126535</td>\n      <td>0.463937</td>\n      <td>-0.302693</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.302568</td>\n      <td>-0.436714</td>\n      <td>-0.078385</td>\n      <td>0.646183</td>\n      <td>-0.507284</td>\n      <td>-1.859351</td>\n      <td>-0.682812</td>\n      <td>-0.572250</td>\n      <td>-0.494941</td>\n      <td>-0.293130</td>\n      <td>...</td>\n      <td>-0.049029</td>\n      <td>0.395018</td>\n      <td>-0.018512</td>\n      <td>3.789876</td>\n      <td>-0.064249</td>\n      <td>-0.09105</td>\n      <td>-0.126535</td>\n      <td>-2.155466</td>\n      <td>-0.302693</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.067331</td>\n      <td>0.689587</td>\n      <td>0.518903</td>\n      <td>1.355551</td>\n      <td>-0.507284</td>\n      <td>0.947203</td>\n      <td>0.753229</td>\n      <td>1.387486</td>\n      <td>0.468931</td>\n      <td>-0.293130</td>\n      <td>...</td>\n      <td>-0.049029</td>\n      <td>0.395018</td>\n      <td>-0.018512</td>\n      <td>-0.263861</td>\n      <td>-0.064249</td>\n      <td>-0.09105</td>\n      <td>-0.126535</td>\n      <td>0.463937</td>\n      <td>-0.302693</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1455</th>\n      <td>0.067331</td>\n      <td>-0.342855</td>\n      <td>-0.285470</td>\n      <td>-0.063185</td>\n      <td>-0.507284</td>\n      <td>0.914184</td>\n      <td>0.753229</td>\n      <td>-0.572250</td>\n      <td>-0.969192</td>\n      <td>-0.293130</td>\n      <td>...</td>\n      <td>-0.049029</td>\n      <td>0.395018</td>\n      <td>-0.018512</td>\n      <td>-0.263861</td>\n      <td>-0.064249</td>\n      <td>-0.09105</td>\n      <td>-0.126535</td>\n      <td>0.463937</td>\n      <td>-0.302693</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1456</th>\n      <td>-0.873616</td>\n      <td>0.736516</td>\n      <td>0.381311</td>\n      <td>-0.063185</td>\n      <td>0.391237</td>\n      <td>0.220801</td>\n      <td>0.178812</td>\n      <td>0.094060</td>\n      <td>0.765338</td>\n      <td>0.670525</td>\n      <td>...</td>\n      <td>-0.049029</td>\n      <td>0.395018</td>\n      <td>-0.018512</td>\n      <td>-0.263861</td>\n      <td>-0.064249</td>\n      <td>-0.09105</td>\n      <td>-0.126535</td>\n      <td>0.463937</td>\n      <td>-0.302693</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1457</th>\n      <td>0.302568</td>\n      <td>-0.155138</td>\n      <td>-0.142806</td>\n      <td>0.646183</td>\n      <td>3.086800</td>\n      <td>-1.000876</td>\n      <td>1.040437</td>\n      <td>-0.572250</td>\n      <td>-0.365400</td>\n      <td>-0.293130</td>\n      <td>...</td>\n      <td>-0.049029</td>\n      <td>0.395018</td>\n      <td>-0.018512</td>\n      <td>-0.263861</td>\n      <td>-0.064249</td>\n      <td>-0.09105</td>\n      <td>-0.126535</td>\n      <td>0.463937</td>\n      <td>-0.302693</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1458</th>\n      <td>-0.873616</td>\n      <td>-0.061280</td>\n      <td>-0.057207</td>\n      <td>-0.772552</td>\n      <td>0.391237</td>\n      <td>-0.703711</td>\n      <td>0.561757</td>\n      <td>-0.572250</td>\n      <td>-0.861608</td>\n      <td>5.790313</td>\n      <td>...</td>\n      <td>-0.049029</td>\n      <td>0.395018</td>\n      <td>-0.018512</td>\n      <td>-0.263861</td>\n      <td>-0.064249</td>\n      <td>-0.09105</td>\n      <td>-0.126535</td>\n      <td>0.463937</td>\n      <td>-0.302693</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1459</th>\n      <td>-0.873616</td>\n      <td>0.267224</td>\n      <td>-0.029308</td>\n      <td>-0.772552</td>\n      <td>0.391237</td>\n      <td>-0.208437</td>\n      <td>-0.922153</td>\n      <td>-0.572250</td>\n      <td>0.853162</td>\n      <td>1.421349</td>\n      <td>...</td>\n      <td>-0.049029</td>\n      <td>0.395018</td>\n      <td>-0.018512</td>\n      <td>-0.263861</td>\n      <td>-0.064249</td>\n      <td>-0.09105</td>\n      <td>-0.126535</td>\n      <td>0.463937</td>\n      <td>-0.302693</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1460 rows Ã— 330 columns</p>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"X_train_df, X_valid_df, y_train_df, y_valid_df = train_test_split(X_train_df, y_train_df, test_size=0.2, random_state=1)\n\nX_train = torch.tensor(X_train_df.values, dtype=torch.float32)\ny_train = torch.tensor(y_train_df.values, dtype=torch.float32).unsqueeze(1)\nX_valid = torch.tensor(X_valid_df.values, dtype=torch.float32)\ny_valid = torch.tensor(y_valid_df.values, dtype=torch.float32).unsqueeze(1)\n\nprint(X_train.shape, y_train.shape)\n\ntrain_ds = TensorDataset(X_train, y_train)\nvalid_ds = TensorDataset(X_valid, y_valid)\n\nbatch_size = 64\n\ntrain_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\nvalid_loader = DataLoader(valid_ds, batch_size=batch_size, shuffle=False)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XK8qWJey9b1Y","outputId":"a7cf003a-5b50-45ae-ed9d-2f253417f12e","trusted":true,"execution":{"iopub.status.busy":"2025-07-31T15:36:27.708419Z","iopub.execute_input":"2025-07-31T15:36:27.708635Z","iopub.status.idle":"2025-07-31T15:36:27.794861Z","shell.execute_reply.started":"2025-07-31T15:36:27.708618Z","shell.execute_reply":"2025-07-31T15:36:27.794240Z"}},"outputs":[{"name":"stdout","text":"torch.Size([1168, 330]) torch.Size([1168, 1])\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"class CustomMLP(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(330, 256),\n            nn.LeakyReLU(0.1),\n            nn.Dropout(0.2),\n            nn.Linear(256, 64),\n            nn.LeakyReLU(0.1),\n            nn.Dropout(0.2),\n            nn.Linear(64, 1),\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\ndef get_gpus():\n    gpu_count = torch.cuda.device_count()\n    return [torch.device(f'cuda:{i}') for i in range(gpu_count)]\n\ndevices = get_gpus()\nprint(devices)\n\nnet = CustomMLP()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"94NVVbpD9b30","outputId":"d7f21dc2-db7c-4318-81b1-e05aec356ae0","trusted":true,"execution":{"iopub.status.busy":"2025-07-31T15:36:27.795489Z","iopub.execute_input":"2025-07-31T15:36:27.796120Z","iopub.status.idle":"2025-07-31T15:36:27.843866Z","shell.execute_reply.started":"2025-07-31T15:36:27.796102Z","shell.execute_reply":"2025-07-31T15:36:27.843324Z"}},"outputs":[{"name":"stdout","text":"[device(type='cuda', index=0), device(type='cuda', index=1)]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"def train(net, dataloader, num_epochs, lr, momentum, devices):\n    net = nn.DataParallel(net, device_ids=devices).to(devices[0])\n\n    loss = nn.MSELoss()\n    optim = torch.optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n\n    for epoch in range(num_epochs):\n        net.train()\n        for X, y in dataloader:\n            X, y = X.to(devices[0]), y.to(devices[0])\n            optim.zero_grad()\n            y_hat = net(X)\n            l = loss(y_hat, y)\n            l.backward()\n            optim.step()\n        if (epoch+1) % 5 == 0:\n            print(f'Epoch {epoch+1} Loss: {l.item():.5f}')\n\ntrain(net, train_loader, 100, lr=0.001, momentum=0.9, devices=devices)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"be57nlBR9b6a","outputId":"21269900-533f-4cb2-dc5b-05bcb2597846","trusted":true,"execution":{"iopub.status.busy":"2025-07-31T15:36:52.922138Z","iopub.execute_input":"2025-07-31T15:36:52.922409Z","iopub.status.idle":"2025-07-31T15:37:06.823031Z","shell.execute_reply.started":"2025-07-31T15:36:52.922390Z","shell.execute_reply":"2025-07-31T15:37:06.822237Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:180.)\n  return F.linear(input, self.weight, self.bias)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 Loss: 2.25123\nEpoch 10 Loss: 3.37110\nEpoch 15 Loss: 3.54134\nEpoch 20 Loss: 2.13126\nEpoch 25 Loss: 1.66895\nEpoch 30 Loss: 1.49272\nEpoch 35 Loss: 1.63901\nEpoch 40 Loss: 1.06410\nEpoch 45 Loss: 4.29376\nEpoch 50 Loss: 0.81860\nEpoch 55 Loss: 2.06815\nEpoch 60 Loss: 0.90963\nEpoch 65 Loss: 1.28576\nEpoch 70 Loss: 0.77915\nEpoch 75 Loss: 0.82414\nEpoch 80 Loss: 0.83678\nEpoch 85 Loss: 0.91088\nEpoch 90 Loss: 1.65972\nEpoch 95 Loss: 1.51636\nEpoch 100 Loss: 0.95176\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"def eval_log_rmse(net, dataloader, devices):\n    net.eval()\n    total_loss, count = 0.0, 0\n\n    with torch.no_grad():\n        for X, y in dataloader:\n            X, y = X.to(devices[0]), y.to(devices[0])\n            y = torch.clamp(y, min=1.0)\n            outputs = net(X)\n            pred = torch.clamp(outputs, min=1.0)\n            loss = torch.sqrt(torch.mean( (torch.log(pred) - torch.log(y) )**2))\n            total_loss += loss.item() * y.size(0)\n            count += y.size(0)\n\n    return total_loss / count\n            \nrmse = eval_log_rmse(net, valid_loader, devices)\nprint(f'Validation accuracy: {rmse:.5f}')","metadata":{"id":"bWwDoYZX9b9L","trusted":true,"execution":{"iopub.status.busy":"2025-07-31T15:37:08.935760Z","iopub.execute_input":"2025-07-31T15:37:08.936183Z","iopub.status.idle":"2025-07-31T15:37:09.151292Z","shell.execute_reply.started":"2025-07-31T15:37:08.936160Z","shell.execute_reply":"2025-07-31T15:37:09.150462Z"}},"outputs":[{"name":"stdout","text":"Validation accuracy: 0.24596\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"X_test_tensor = torch.tensor(X_test_df.values, dtype=torch.float32).to(devices[0])\n\nnet.eval()\nwith torch.no_grad():\n    preds = net(X_test_tensor).squeeze(1).cpu().numpy()\n\nhouse_ids = pd.read_csv(os.path.join(input_dir, 'test.csv'))['Id']\n\nsubmission = pd.DataFrame({\n    'Id': house_ids,\n    'SalePrice': np.expm1(preds).squeeze()\n})\nprint(submission)\nsubmission.to_csv('submission.csv', index=False)","metadata":{"id":"h-fn7crHA-1-","trusted":true,"execution":{"iopub.status.busy":"2025-07-31T15:37:11.427062Z","iopub.execute_input":"2025-07-31T15:37:11.427325Z","iopub.status.idle":"2025-07-31T15:37:11.465078Z","shell.execute_reply.started":"2025-07-31T15:37:11.427304Z","shell.execute_reply":"2025-07-31T15:37:11.464383Z"}},"outputs":[{"name":"stdout","text":"        Id      SalePrice\n0     1461   55909.746094\n1     1462   15938.531250\n2     1463  170394.812500\n3     1464   94239.445312\n4     1465  210807.046875\n...    ...            ...\n1454  2915   49645.968750\n1455  2916   44455.550781\n1456  2917  169528.140625\n1457  2918   90549.406250\n1458  2919  129695.460938\n\n[1459 rows x 2 columns]\n","output_type":"stream"}],"execution_count":8}]}