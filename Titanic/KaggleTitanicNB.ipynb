{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfrom sklearn.preprocessing import StandardScaler\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torch import nn\nfrom sklearn.model_selection import train_test_split\n\ninput_dir = '/kaggle/input/titanic/'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-30T18:32:01.965279Z","iopub.execute_input":"2025-07-30T18:32:01.965622Z","iopub.status.idle":"2025-07-30T18:32:14.433066Z","shell.execute_reply.started":"2025-07-30T18:32:01.965597Z","shell.execute_reply":"2025-07-30T18:32:14.432272Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def read_and_preprocess_csv(titanic_dir):\n    '''\n    Reads and preprocesses train and test csv's\n\n    Args:\n        titanic_dir (str): directory of the titanic dataset\n\n    Returns:\n        X_train (pd.DataFrame): input for the model training\n        y_train (pd.Series): labels for training\n        X_test (pd.DataFrame): input for the model testing\n    '''\n    train_csv = pd.read_csv(os.path.join(titanic_dir, 'train.csv'))\n    test_csv = pd.read_csv(os.path.join(titanic_dir, 'test.csv'))\n    \n    ground_truth = 'Survived'\n    features = pd.concat(\n        (train_csv.drop(columns=['PassengerId', ground_truth]),\n         test_csv.drop(columns=['PassengerId'])))\n    numerical_features = features.dtypes[features.dtypes != 'object'].index\n    \n    # print(numerical_features)\n    \n    features[numerical_features] = features[numerical_features].fillna(0)\n\n    # apply standardization to features (x - x.mean() / x.std())\n    scaler = StandardScaler()\n    features[numerical_features] = scaler.fit_transform(features[numerical_features])\n    \n    print(f'Shape before get_dummies: {features.shape}')\n    features = pd.get_dummies(features, dummy_na=True)\n    print(f'Shape after get_dummies: {features.shape}')\n    # print(features.dtypes[features.dtypes == 'object'])\n\n    features = features.astype('float32')\n    \n    y_train = train_csv[ground_truth]\n    \n    X_train = features.iloc[:len(y_train)]\n    X_test = features.iloc[len(y_train):]\n    \n    return X_train, y_train, X_test\n    \nX_train_df, y_train_df, X_test_df = read_and_preprocess_csv(os.path.join(input_dir))\n\nprint(X_train_df.shape,y_train_df.shape, X_test_df.shape)\nX_train_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T18:32:14.433911Z","iopub.execute_input":"2025-07-30T18:32:14.434294Z","iopub.status.idle":"2025-07-30T18:32:14.563728Z","shell.execute_reply.started":"2025-07-30T18:32:14.434275Z","shell.execute_reply":"2025-07-30T18:32:14.562922Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_df, X_valid_df, y_train_df, y_valid_df = train_test_split(X_train_df, y_train_df, test_size=0.2, random_state=1)\n\nX_train = torch.tensor(X_train_df.values, dtype=torch.float32)\ny_train = torch.tensor(y_train_df.values, dtype=torch.float32).unsqueeze(1)\nX_valid = torch.tensor(X_valid_df.values, dtype=torch.float32)\ny_valid = torch.tensor(y_valid_df.values, dtype=torch.float32).unsqueeze(1)\nprint(X_train.shape, y_train.shape)\ntrain_ds = TensorDataset(X_train, y_train)\nvalid_ds = TensorDataset(X_valid, y_valid)\nbatch_size = 64\ntrain_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\nvalid_loader = DataLoader(valid_ds, batch_size=batch_size, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T18:32:14.565808Z","iopub.execute_input":"2025-07-30T18:32:14.566077Z","iopub.status.idle":"2025-07-30T18:32:14.669007Z","shell.execute_reply.started":"2025-07-30T18:32:14.566059Z","shell.execute_reply":"2025-07-30T18:32:14.668333Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CustomMLP(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(2437, 256),\n            nn.LeakyReLU(0.1),\n            nn.Linear(256, 64),\n            nn.LeakyReLU(0.1),\n            nn.Linear(64, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\ndef get_gpus():\n    gpu_count = torch.cuda.device_count()\n    return [torch.device(f'cuda:{i}') for i in range(gpu_count)]\n\ndevices = get_gpus()\nprint(devices)\n\nnet = CustomMLP()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T18:32:14.669741Z","iopub.execute_input":"2025-07-30T18:32:14.670725Z","iopub.status.idle":"2025-07-30T18:32:14.730949Z","shell.execute_reply.started":"2025-07-30T18:32:14.670703Z","shell.execute_reply":"2025-07-30T18:32:14.730327Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train(net, dataloader, num_epochs, lr, lr_period, lr_decay, momentum, devices):\n    net = nn.DataParallel(net, device_ids=devices).to(devices[0])\n\n    loss = nn.BCELoss()\n    optim = torch.optim.SGD(net.parameters(), lr=lr, momentum=momentum) \n\n    scheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=lr_period, gamma=lr_decay)\n    \n    for epoch in range(num_epochs):\n        net.train()\n        for X, y in dataloader:\n            X, y = X.to(devices[0]), y.to(torch.float32).to(devices[0])\n            optim.zero_grad()\n            y_hat = net(X)\n            l = loss(y_hat, y)\n            l.backward()\n            optim.step()\n        scheduler.step()\n        if (epoch+1) % 5 == 0:\n            print(f'Epoch {epoch + 1} Loss: {l.item():.4f}')\n\n\ntrain(net, train_loader, 100, lr=0.1, momentum=0.9, devices=devices, lr_period=5, lr_decay=0.99)\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T18:32:14.731657Z","iopub.execute_input":"2025-07-30T18:32:14.731920Z","iopub.status.idle":"2025-07-30T18:32:27.278881Z","shell.execute_reply.started":"2025-07-30T18:32:14.731901Z","shell.execute_reply":"2025-07-30T18:32:27.278095Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def eval_acc(net, dataloader, devices):\n    net.eval()\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for X, y in dataloader:\n            X = X.to(devices[0])\n            y = y.to(devices[0])\n            outputs = net(X)\n            preds = (outputs > 0.5).float()\n            correct += (preds == y).sum().item()\n            total += y.size(0)\n\n    return correct / total\n\nacc = eval_acc(net, valid_loader, devices)\nprint(f'Validation accuracy: {acc:.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T18:32:27.279771Z","iopub.execute_input":"2025-07-30T18:32:27.280640Z","iopub.status.idle":"2025-07-30T18:32:27.389975Z","shell.execute_reply.started":"2025-07-30T18:32:27.280604Z","shell.execute_reply":"2025-07-30T18:32:27.389356Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test_tensor = torch.tensor(X_test_df.values, dtype=torch.float32).to(devices[0])\nnet.eval()\nwith torch.no_grad():\n    preds = net(X_test_tensor)\n    preds = (preds > 0.5).int().squeeze().cpu().numpy()\n\npassenger_ids = pd.read_csv(os.path.join(input_dir, 'test.csv'))['PassengerId']\n\nsubmission = pd.DataFrame({\n    'PassengerId': passenger_ids,\n    'Survived': preds\n})\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T18:32:27.390654Z","iopub.execute_input":"2025-07-30T18:32:27.390920Z","iopub.status.idle":"2025-07-30T18:32:27.415426Z","shell.execute_reply.started":"2025-07-30T18:32:27.390893Z","shell.execute_reply":"2025-07-30T18:32:27.414860Z"}},"outputs":[],"execution_count":null}]}